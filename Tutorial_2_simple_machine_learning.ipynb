{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up a Neural Networks \n",
    "set up MNIST data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (60000, 784)\n",
      "y_train.shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# set up MNIST data sets, required keras lib\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)/255.0\n",
    "X_test = X_test.reshape(10000, 784)/255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train.shape',X_train.shape)\n",
    "print('y_train.shape',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import reikna.cluda as cluda\n",
    "from reikna.core import Type\n",
    "from reikna.cbrng import CBRNG\n",
    "from reikna.cbrng.samplers import uniform_float\n",
    "from reikna.cbrng.bijections import threefry\n",
    "\n",
    "api = cluda.ocl_api()#ocl_api()#.cuda_api() switch opencl and cuda\n",
    "thr = api.Thread.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before random set\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "after random set\n",
      "[[  7.32800841e-01   8.28513563e-01   5.42470515e-01 ...,   7.22194314e-01\n",
      "    6.18905425e-01   5.99146783e-01]\n",
      " [  3.99667680e-01   2.76426405e-01   3.96757483e-01 ...,   3.25989783e-01\n",
      "    1.95984095e-01   6.40559010e-04]\n",
      " [  9.37009275e-01   6.49996817e-01   3.28292876e-01 ...,   9.54684675e-01\n",
      "    4.18014288e-01   7.68346786e-01]\n",
      " ..., \n",
      " [  7.48250246e-01   2.66601145e-01   9.70116079e-01 ...,   3.01580012e-01\n",
      "    8.58210742e-01   6.39033556e-01]\n",
      " [  9.61607039e-01   5.93545675e-01   2.29457393e-01 ...,   2.07748637e-01\n",
      "    9.61972833e-01   8.11869085e-01]\n",
      " [  5.91419935e-01   1.44220488e-02   4.18172687e-01 ...,   8.73038411e-01\n",
      "    3.65534961e-01   3.94895285e-01]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = '-1'\n",
    "'input :784 units, output layer:10 units'\n",
    "layers=(784, 10)\n",
    "NN = np.zeros(layers).astype(np.float32)\n",
    "NN_dev = thr.to_device(NN)\n",
    "print('before random set')\n",
    "print(NN_dev.get())\n",
    "\n",
    "'set up GPU random set Neural Networks fun'\n",
    "rng = CBRNG(Type(np.float32 , shape=layers), 1, uniform_float(threefry(32, 4), np.float32 ))\n",
    "counters_dev = thr.to_device(rng.create_counters())\n",
    "GPU_randomSet=rng.compile(thr)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "print()\n",
    "print('after random set')\n",
    "print(NN_dev.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rearrange the weights in [ -1 , 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_rearrange(\n",
    "    GLOBAL_MEM float *input,\n",
    "    const float from,\n",
    "    const float to\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    input[IDX] = from+input[IDX] * (to-from) ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUrearrange = program.gpu_rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46560168,  0.65702713,  0.08494103, ...,  0.44438863,\n",
       "         0.23781085,  0.19829357],\n",
       "       [-0.20066464, -0.44714719, -0.20648503, ..., -0.34802043,\n",
       "        -0.60803181, -0.99871886],\n",
       "       [ 0.87401855,  0.29999363, -0.34341425, ...,  0.90936935,\n",
       "        -0.16397142,  0.53669357],\n",
       "       ..., \n",
       "       [ 0.49650049, -0.46679771,  0.94023216, ..., -0.39683998,\n",
       "         0.71642148,  0.27806711],\n",
       "       [ 0.92321408,  0.18709135, -0.54108524, ..., -0.5845027 ,\n",
       "         0.92394567,  0.62373817],\n",
       "       [ 0.18283987, -0.97115588, -0.16365463, ...,  0.74607682,\n",
       "        -0.26893008, -0.21020943]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUrearrange(NN_dev, (np.float32)(-1.0), (np.float32)(1.0), local_size=(1,1), global_size=NN_dev.shape)\n",
    "NN_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up GPU feedforward fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reikna.linalg import MatrixMul\n",
    "'set up GPU feedforward fun'\n",
    "batchSize = 3000\n",
    "getRandBatch = lambda : np.random.choice(np.arange(len(X_train)),batchSize).astype(np.int32)\n",
    "\n",
    "batchTrain = X_train[getRandBatch(),:].copy().astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "predict_dev = thr.array((batchSize,layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUfeedforward = MatrixMul(batchTrain_dev, NN_dev, out_arr=predict_dev).compile(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.73258877 -2.45554996  1.83694613 ..., -3.51368475 -4.25749969\n",
      "   1.54934692]\n",
      " [ 4.49922514  0.65834707  9.97752953 ..., -1.88652945 -0.33362553\n",
      "  -3.00773001]\n",
      " [ 3.848526   -4.36007071  9.3614769  ...,  6.2664299  -6.49548721\n",
      "  -7.46111631]\n",
      " ..., \n",
      " [ 3.20629644 -0.84305209  2.04479122 ..., -9.59047508 -1.53382289\n",
      "  -5.06183577]\n",
      " [-1.09001207 -0.83752155 -2.12862182 ..., -3.34624171 -1.56633997\n",
      "   1.45993412]\n",
      " [ 2.57909489  1.7980994   0.74181187 ...,  1.27912402  6.56489849\n",
      "  -7.73308754]]\n",
      "Check GPU result with CPU result if they are the same :\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "print(predict_dev)\n",
    "print(\"Check GPU result with CPU result if they are the same :\")\n",
    "print(np.linalg.norm(predict_dev.get() - batchTrain.dot(NN_dev.get())) / np.linalg.norm(batchTrain.dot(NN_dev.get())) < 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-reading: http://cs231n.github.io/linear-classify/#softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.42055795e-07,   8.47011165e-07,   6.19579005e-05, ...,\n",
       "          2.93999705e-07,   1.39737310e-07,   4.64722689e-05],\n",
       "       [  1.41008140e-03,   3.02811277e-05,   3.37630421e-01, ...,\n",
       "          2.37654695e-06,   1.12295857e-05,   7.74488853e-07],\n",
       "       [  3.80493514e-03,   1.03609295e-06,   9.43172991e-01, ...,\n",
       "          4.27001640e-02,   1.22461444e-07,   4.66263863e-08],\n",
       "       ..., \n",
       "       [  2.21340675e-02,   3.85879393e-04,   6.92828791e-03, ...,\n",
       "          6.13047249e-08,   1.93398664e-04,   5.67880306e-06],\n",
       "       [  1.05689876e-02,   1.36046885e-02,   3.74085526e-03, ...,\n",
       "          1.10704510e-03,   6.56397175e-03,   1.35350823e-01],\n",
       "       [  4.95724613e-03,   2.27017049e-03,   7.89438898e-04, ...,\n",
       "          1.35104673e-03,   2.66841263e-01,   1.64708695e-07]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU softmax fun'\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_softmax(\n",
    "    GLOBAL_MEM float *input\n",
    "    )\n",
    "{\n",
    "    const SIZE_T i0 = get_global_id(0);\n",
    "    const SIZE_T i1 = get_global_id(1);\n",
    "    //why terminate?  because softmax need to sum up from [i,0] to [i,end]\n",
    "    if(i1>0)return;\n",
    "\n",
    "    int IDX = i0*get_global_size(1)+i1;\n",
    "    float s = 0.0f;\n",
    "    float max = 0.0f;\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "        if(max<input[IDX+i])max=input[IDX+i];\n",
    "    };\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "      input[IDX+i]=exp(input[IDX+i]-max);\n",
    "      s+=input[IDX+i];\n",
    "    };\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "      input[IDX+i]/=s;\n",
    "    };\n",
    "}\n",
    "\"\"\")\n",
    "GPUsoftmax = program.gpu_softmax\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "predict_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.53711075e-01,   4.58997056e-06,   5.70994765e-02, ...,\n",
       "         -9.99999404e-01,   7.84337608e-05,   6.61649287e-01],\n",
       "       [  8.42314184e-01,   3.19325886e-06,   9.87458900e-02, ...,\n",
       "          3.13316741e-05,   8.44048486e-07,   2.50185898e-04],\n",
       "       [  7.51112704e-04,  -9.98892307e-01,   5.49790263e-02, ...,\n",
       "          1.35208402e-05,   9.70839551e-07,   2.05836864e-03],\n",
       "       ..., \n",
       "       [  1.08720349e-06,   4.73830570e-03,  -9.98037875e-01, ...,\n",
       "          4.05637650e-07,   4.03369768e-07,   4.98181616e-05],\n",
       "       [  3.38208564e-02,   9.27042711e-05,   9.65389669e-01, ...,\n",
       "          1.06395625e-07,   1.24160419e-04,   3.87191860e-04],\n",
       "       [  1.01235946e-05,   3.74680189e-06,   2.94366419e-05, ...,\n",
       "          1.44698337e-04,   6.81707636e-02,   6.25829995e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchIdx = getRandBatch()\n",
    "batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "GPUrearrange(NN_dev, (np.float32)(-1), (np.float32)(1), local_size=(1,1), global_size=NN_dev.shape)\n",
    "\n",
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "errors_dev=(predict_dev-batchTrainLabels_dev)\n",
    "errors_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.cffi_cl.Event at 0x13bd24630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"get errors like this : errors_dev=batchTrainLabels_dev-predict_dev\"\n",
    "\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_minus(\n",
    "    GLOBAL_MEM float *a_dev,\n",
    "    GLOBAL_MEM float *b_dev,\n",
    "    GLOBAL_MEM float *res_dev\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    res_dev[IDX] = a_dev[IDX] - b_dev[IDX] ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUminus = program.gpu_minus\n",
    "GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278.229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU errors back fun'\n",
    "errors_back_dev = thr.array((layers[0],layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUerrorsBack = MatrixMul(batchTrain_dev, errors_dev, out_arr=errors_back_dev, transposed_a=True).compile(thr)\n",
    "GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "errors_back_dev.get().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.cffi_cl.Event at 0x13bd24ef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"update weights like this : NN_dev+= lr * errors_back_dev/batchSize\"\n",
    "lr = 1e-3\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_updateW(\n",
    "    GLOBAL_MEM float *NN_dev,\n",
    "    GLOBAL_MEM float *errors_back_dev,\n",
    "    const float lr,\n",
    "    const float batchSize\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    NN_dev[IDX] += lr * errors_back_dev[IDX]/batchSize ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUupdateW = program.gpu_updateW\n",
    "GPUupdateW(NN_dev, errors_back_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.cffi_cl.Event at 0x13bdb0ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "GPUrearrange(NN_dev, (np.float32)(0), (np.float32)(0.1), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8666666667\n",
      "cost time: 2.0018649101257324\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "# batchTrain_dev = thr.to_device(X_train[:,:].astype(np.float32))\n",
    "# batchTrainLabels_dev = thr.to_device(y_train[:,:].astype(np.float32))\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "    GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "    GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "    GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)\n",
    "    GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "    GPUupdateW(NN_dev, errors_back_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=NN_dev.shape)\n",
    "    if i%100 == 0:\n",
    "        print((np.argmax(predict_dev.get(),1)==np.argmax(batchTrainLabels_dev.get(),1)).sum()/batchSize*100)\n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. make a CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    tmp=np.exp(x-x.max(1).reshape(-1,1))\n",
    "    return tmp/tmp.sum(1).reshape(-1,1)\n",
    "NN=NN_dev.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 22.3666666667\n",
      "cost time: 1.7499561309814453\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "# batchTrain = X_train[:,:].astype(np.float32)\n",
    "# batchTrainLabels = y_train[:,:].astype(np.float32)\n",
    "import time\n",
    "start = time.time()\n",
    "for j in range((int)(1e2)):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    \n",
    "    y = softmax(batchTrain.dot(NN))\n",
    "    error = batchTrainLabels - y\n",
    "    NN += batchTrain.T.dot(error)/batchSize * lr\n",
    "    \n",
    "    if (j% 100) == 0:\n",
    "        print(\"acc:\",(np.argmax(y,1)==np.argmax(batchTrainLabels,1)).sum()/batchSize*100)   \n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CPU is faster than GPU !!!\n",
    "\n",
    "The main reson here is that X_train data transformation ( to_device() ) cost too much time.\n",
    "\n",
    "Try to restart kernel and use full train data set which just need one time transformation ( to_device() ).\n",
    "\n",
    "CPU 100 times : cost time: 7.946720123291016\n",
    "\n",
    "GPU 100 times : cost time: 0.19799399375915527"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial seems a little difficult. But CPU version shows this machine learning is no so complex.(except some math things)\n",
    "\n",
    "If you give a read of GPU codes only, you will find that things at GPU are also simple.\n",
    "\n",
    "Next tutorial will introduce Genetic Algorithm, which dose not have a GPU solution at python but easy to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

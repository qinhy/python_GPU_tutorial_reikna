{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up a Neural Networks \n",
    "set up MNIST data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (60000, 784)\n",
      "y_train.shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# set up MNIST data sets, required keras lib\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)/255.0\n",
    "X_test = X_test.reshape(10000, 784)/255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train.shape',X_train.shape)\n",
    "print('y_train.shape',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import reikna.cluda as cluda\n",
    "from reikna.core import Type\n",
    "from reikna.cbrng import CBRNG\n",
    "from reikna.cbrng.samplers import uniform_float\n",
    "from reikna.cbrng.bijections import threefry\n",
    "\n",
    "api = cluda.ocl_api()#ocl_api()#.cuda_api() switch opencl and cuda\n",
    "thr = api.Thread.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before random set\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "after random set\n",
      "[[ 0.08641637  0.90209508  0.62375396 ...,  0.91747504  0.25345078\n",
      "   0.09279578]\n",
      " [ 0.72694129  0.47865188  0.01610436 ...,  0.96699399  0.86852717\n",
      "   0.48502406]\n",
      " [ 0.222192    0.93154973  0.27536535 ...,  0.96508378  0.54829693\n",
      "   0.88557684]\n",
      " ..., \n",
      " [ 0.08711699  0.15364091  0.27513865 ...,  0.94850802  0.26529047\n",
      "   0.10553091]\n",
      " [ 0.81097257  0.95353609  0.65544355 ...,  0.93285435  0.40868947\n",
      "   0.06189557]\n",
      " [ 0.95610756  0.24175578  0.44507435 ...,  0.35118732  0.38971031\n",
      "   0.7225948 ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = '-1'\n",
    "'input :784 units, output layer:10 units'\n",
    "layers=(784, 10)\n",
    "NN = np.zeros(layers).astype(np.float32)\n",
    "NN_dev = thr.to_device(NN)\n",
    "print('before random set')\n",
    "print(NN_dev.get())\n",
    "\n",
    "'set up GPU random set Neural Networks fun'\n",
    "rng = CBRNG(Type(np.float32 , shape=layers), 1, uniform_float(threefry(32, 4), np.float32 ))\n",
    "counters_dev = thr.to_device(rng.create_counters())\n",
    "GPU_randomSet=rng.compile(thr)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "print()\n",
    "print('after random set')\n",
    "print(NN_dev.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rearrange the weights in [ -1 , 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_rearrange(\n",
    "    GLOBAL_MEM float *input,\n",
    "    const float from,\n",
    "    const float to\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    input[IDX] = from+input[IDX] * (to-from) ; // calculate product value, it can be +,/,<... etc.\n",
    "}\n",
    "\"\"\")\n",
    "#have attention to the function name if it is same as above\n",
    "GPUrearrange = program.gpu_rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.82716727,  0.80419016,  0.24750793, ...,  0.83495009,\n",
       "        -0.49309844, -0.81440842],\n",
       "       [ 0.45388258, -0.04269624, -0.96779126, ...,  0.93398798,\n",
       "         0.73705435, -0.02995187],\n",
       "       [-0.55561602,  0.86309946, -0.44926929, ...,  0.93016756,\n",
       "         0.09659386,  0.77115369],\n",
       "       ..., \n",
       "       [-0.82576603, -0.69271815, -0.44972271, ...,  0.89701605,\n",
       "        -0.46941906, -0.78893816],\n",
       "       [ 0.62194514,  0.90707219,  0.3108871 , ...,  0.86570871,\n",
       "        -0.18262106, -0.87620884],\n",
       "       [ 0.91221511, -0.51648843, -0.1098513 , ..., -0.29762536,\n",
       "        -0.22057939,  0.4451896 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUrearrange(NN_dev, (np.float32)(-1.0), (np.float32)(1.0), local_size=(1,1), global_size=NN_dev.shape)\n",
    "NN_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up GPU feedforward fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reikna.linalg import MatrixMul\n",
    "'set up GPU feedforward fun'\n",
    "batchSize = 3000\n",
    "getRandBatch = lambda : np.random.choice(np.arange(len(X_train)),batchSize)\n",
    "\n",
    "batchTrain = X_train[getRandBatch(),:].copy().astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "predict_dev = thr.array((batchSize,layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUfeedforward = MatrixMul(batchTrain_dev, NN_dev, out_arr=predict_dev).compile(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.54050255e+00  -2.77163315e+00  -8.97107983e+00 ...,  -4.37363815e+00\n",
      "   -5.39937496e+00   2.37878108e+00]\n",
      " [ -4.75659227e+00  -4.12313223e+00  -3.85019755e+00 ...,  -8.35910261e-01\n",
      "   -7.29273272e+00  -7.66714621e+00]\n",
      " [ -2.36363101e+00  -5.04455614e+00  -6.03383493e+00 ...,  -5.89509428e-01\n",
      "   -4.30992365e+00  -6.30287266e+00]\n",
      " ..., \n",
      " [ -7.79163408e+00   4.09991056e-01  -1.82047501e+01 ...,  -2.44125462e+00\n",
      "    2.19995594e+00   8.05452228e-01]\n",
      " [ -9.77492237e+00  -2.42421460e+00   6.35660112e-01 ...,   6.26923609e+00\n",
      "    8.61009210e-03   1.02177513e+00]\n",
      " [ -3.30745697e+00  -7.00298643e+00  -9.92344093e+00 ...,   9.89926338e+00\n",
      "   -4.15765858e+00  -4.97645140e+00]]\n",
      "Check GPU result with CPU result if they are the same :\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "print(predict_dev)\n",
    "print(\"Check GPU result with CPU result if they are the same :\")\n",
    "print(np.linalg.norm(predict_dev.get() - batchTrain.dot(NN_dev.get())) / np.linalg.norm(batchTrain.dot(NN_dev.get())) < 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-reading: http://cs231n.github.io/linear-classify/#softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08838614,  0.08839467,  0.08838559, ...,  0.08838741,\n",
       "         0.08838623,  0.08996862],\n",
       "       [ 0.08768382,  0.08768389,  0.08768395, ...,  0.0876884 ,\n",
       "         0.08768373,  0.08768373],\n",
       "       [ 0.08725574,  0.08657068,  0.08653916, ...,  0.09094588,\n",
       "         0.08662512,  0.08653475],\n",
       "       ..., \n",
       "       [ 0.08533687,  0.08533698,  0.08533687, ...,  0.08533688,\n",
       "         0.08533749,  0.08533702],\n",
       "       [ 0.08741203,  0.08742375,  0.08766253, ...,  0.19459687,\n",
       "         0.08754575,  0.08778082],\n",
       "       [ 0.08562313,  0.08562313,  0.08562313, ...,  0.08765012,\n",
       "         0.08562313,  0.08562313]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU softmax fun'\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_softmax(\n",
    "    GLOBAL_MEM float *input\n",
    "    )\n",
    "{\n",
    "    const SIZE_T i0 = get_global_id(0);\n",
    "    const SIZE_T i1 = get_global_id(1);\n",
    "    //why terminate?  because softmax need to sum up from [i,0] to [i,end]\n",
    "    if(i1>0)return;\n",
    "\n",
    "    int IDX = i0*get_global_size(1)+i1;\n",
    "    float s = 0.0f;\n",
    "    float max = 0.0f;\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "        if(max<input[IDX+i])max=input[IDX+i];\n",
    "    }\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "      input[IDX+i]=exp(input[IDX+i]-max);\n",
    "      s+=input[IDX+i];\n",
    "    };\n",
    "    for(int i=0;i<(int)get_global_size(1);i++){\n",
    "      input[IDX+i]/=s;\n",
    "    };\n",
    "}\n",
    "\"\"\")\n",
    "GPUsoftmax = program.gpu_softmax\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "predict_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.10526034e-03,   2.36217733e-02,   3.41599365e-03, ...,\n",
       "         -9.87945318e-01,   1.69304222e-01,   1.57591549e-03],\n",
       "       [  6.69368878e-02,   5.01299463e-03,   3.07187557e-01, ...,\n",
       "         -7.53791332e-01,   8.32950845e-02,   2.66553257e-02],\n",
       "       [  1.71011857e-06,   7.38984440e-04,   6.61693321e-06, ...,\n",
       "          1.13188245e-04,   2.92522600e-04,   2.29449256e-06],\n",
       "       ..., \n",
       "       [ -9.99879658e-01,   8.34345166e-03,   1.51391199e-04, ...,\n",
       "          1.00565485e-05,   2.00507187e-04,   1.46632592e-05],\n",
       "       [  2.39652756e-04,   1.04264647e-01,   2.77398364e-03, ...,\n",
       "          1.43363429e-02,   1.28449360e-02,   1.52608831e-04],\n",
       "       [  8.57720908e-04,   6.90310895e-01,   6.23268681e-03, ...,\n",
       "          4.25609313e-02,   9.19866040e-02,   5.38685685e-03]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchIdx = getRandBatch()\n",
    "batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "# GPUrearrange(NN_dev, (np.float32)(0), (np.float32)(0.1), local_size=(1,1), global_size=NN_dev.shape)\n",
    "\n",
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "'calculate errors cross entropy'\n",
    "errors_dev=(predict_dev-batchTrainLabels_dev)\n",
    "errors_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"get errors like this : errors_dev=batchTrainLabels_dev-predict_dev\"\n",
    "\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_minus(\n",
    "    GLOBAL_MEM float *a_dev,\n",
    "    GLOBAL_MEM float *b_dev,\n",
    "    GLOBAL_MEM float *res_dev\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    res_dev[IDX] = a_dev[IDX] - b_dev[IDX] ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUminus = program.gpu_minus\n",
    "GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217.10446"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU errors back fun'\n",
    "errors_back_dev = thr.array((layers[0],layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUerrorsBack = MatrixMul(batchTrain_dev, errors_dev, out_arr=errors_back_dev, transposed_a=True).compile(thr)\n",
    "GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "errors_back_dev.get().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"update weights like this : NN_dev+= lr * errors_back_dev/batchSize\"\n",
    "\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_updateW(\n",
    "    GLOBAL_MEM float *NN_dev,\n",
    "    GLOBAL_MEM float *errors_back_dev,\n",
    "    const float lr,\n",
    "    const float batchSize\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    NN_dev[IDX] += lr * errors_back_dev[IDX]/batchSize ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUupdateW = program.gpu_updateW\n",
    "GPUupdateW(NN_dev, errors_back_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "GPUrearrange(NN_dev, (np.float32)(0), (np.float32)(0.1), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time: 3.9852280616760254\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "# batchTrain_dev = thr.to_device(X_train[:,:].astype(np.float32))\n",
    "# batchTrainLabels_dev = thr.to_device(y_train[:,:].astype(np.float32))\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "    GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "    GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "    'calculate errors cross entropy'\n",
    "    GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)\n",
    "    GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "#     errors_mean_dev=errors_back_dev/batchSize\n",
    "    GPUupdateW(NN_dev, errors_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=errors_dev.shape)\n",
    "#     if i%100 == 0:\n",
    "#         print((np.argmax(predict_dev.get(),1)==np.argmax(batchTrainLabels,1)).sum()/batchSize*100)\n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. make a CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    tmp=np.exp(x-x.max(1).reshape(-1,1))\n",
    "    return tmp/tmp.sum(1).reshape(-1,1)\n",
    "NN=NN_dev.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9 ms\n",
      "Wall time: 3 ms\n",
      "Wall time: 27 ms\n",
      "acc: 14.9\n",
      "cost time: 0.0760042667388916\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "# batchTrain = X_train[:,:].astype(np.float32)\n",
    "# batchTrainLabels = y_train[:,:].astype(np.float32)\n",
    "import time\n",
    "start = time.time()\n",
    "for j in range((int)(1e0)):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    \n",
    "    y = softmax(batchTrain.dot(NN))\n",
    "    error = batchTrainLabels - y\n",
    "    NN += batchTrain.T.dot(error)/batchSize * lr\n",
    "    \n",
    "    if (j% 100) == 0:\n",
    "        print(\"acc:\",(np.argmax(y,1)==np.argmax(batchTrainLabels,1)).sum()/batchSize*100)   \n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

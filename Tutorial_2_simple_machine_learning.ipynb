{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up a Neural Networks \n",
    "set up MNIST data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (60000, 784)\n",
      "y_train.shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# set up MNIST data sets, required keras lib\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)/255.0\n",
    "X_test = X_test.reshape(10000, 784)/255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train.shape',X_train.shape)\n",
    "print('y_train.shape',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import reikna.cluda as cluda\n",
    "from reikna.core import Type\n",
    "from reikna.cbrng import CBRNG\n",
    "from reikna.cbrng.samplers import uniform_float\n",
    "from reikna.cbrng.bijections import threefry\n",
    "\n",
    "api = cluda.cuda_api()#ocl_api()#.cuda_api() switch opencl and cuda\n",
    "thr = api.Thread.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before random set\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "after random set\n",
      "[[ 0.12403855  0.02336662  0.59507793 ...,  0.09912867  0.13376518\n",
      "   0.83598381]\n",
      " [ 0.49977431  0.38667753  0.17460006 ...,  0.11854074  0.23574686\n",
      "   0.53133935]\n",
      " [ 0.84471881  0.56952435  0.06624993 ...,  0.98948461  0.56452423\n",
      "   0.04352978]\n",
      " ..., \n",
      " [ 0.36141056  0.64748794  0.9488861  ...,  0.28697175  0.60381103\n",
      "   0.89384705]\n",
      " [ 0.43408123  0.8563509   0.53729534 ...,  0.80452663  0.39777288\n",
      "   0.3031466 ]\n",
      " [ 0.80537182  0.9238919   0.13718309 ...,  0.68108571  0.78619164\n",
      "   0.42821193]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = '-1'\n",
    "'input :784 units, output layer:10 units'\n",
    "layers=(784, 10)\n",
    "NN = np.zeros(layers).astype(np.float32)\n",
    "NN_dev = thr.to_device(NN)\n",
    "print('before random set')\n",
    "print(NN_dev.get())\n",
    "\n",
    "'set up GPU random set Neural Networks fun'\n",
    "rng = CBRNG(Type(np.float32 , shape=layers), 1, uniform_float(threefry(32, 4), np.float32 ))\n",
    "counters_dev = thr.to_device(rng.create_counters())\n",
    "GPU_randomSet=rng.compile(thr)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "print()\n",
    "print('after random set')\n",
    "print(NN_dev.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rearrange the weights in [ -1 , 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_rearrange(\n",
    "    GLOBAL_MEM float *input,\n",
    "    const float from,\n",
    "    const float to\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    input[IDX] = from+input[IDX] * (to-from) ; // calculate product value, it can be +,/,<... etc.\n",
    "}\n",
    "\"\"\")\n",
    "#have attention to the function name if it is same as above\n",
    "GPUrearrange = program.gpu_rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.51922905e-01,  -9.53266740e-01,   1.90155864e-01, ...,\n",
       "         -8.01742673e-01,  -7.32469678e-01,   6.71967626e-01],\n",
       "       [ -4.51385975e-04,  -2.26644933e-01,  -6.50799870e-01, ...,\n",
       "         -7.62918532e-01,  -5.28506279e-01,   6.26786947e-02],\n",
       "       [  6.89437628e-01,   1.39048696e-01,  -8.67500126e-01, ...,\n",
       "          9.78969216e-01,   1.29048467e-01,  -9.12940443e-01],\n",
       "       ..., \n",
       "       [ -2.77178884e-01,   2.94975877e-01,   8.97772193e-01, ...,\n",
       "         -4.26056504e-01,   2.07622051e-01,   7.87694097e-01],\n",
       "       [ -1.31837547e-01,   7.12701797e-01,   7.45906830e-02, ...,\n",
       "          6.09053254e-01,  -2.04454243e-01,  -3.93706799e-01],\n",
       "       [  6.10743642e-01,   8.47783804e-01,  -7.25633860e-01, ...,\n",
       "          3.62171412e-01,   5.72383285e-01,  -1.43576145e-01]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUrearrange(NN_dev, (np.float32)(-1.0), (np.float32)(1.0), local_size=(1,1), global_size=NN_dev.shape)\n",
    "NN_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up GPU feedforward fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reikna.linalg import MatrixMul\n",
    "'set up GPU feedforward fun'\n",
    "batchSize = 3000\n",
    "getRandBatch = lambda : np.random.choice(np.arange(len(X_train)),batchSize)\n",
    "\n",
    "batchTrain = X_train[getRandBatch(),:].copy().astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "predict_dev = thr.array((batchSize,layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUfeedforward = MatrixMul(batchTrain_dev, NN_dev, out_arr=predict_dev).compile(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.61323667   2.01963687   3.31880426 ...,  10.61067677  -3.63300228\n",
      "   -1.79879069]\n",
      " [-12.04747677  -1.93427289   3.86403012 ...,   4.32552052  -4.82424212\n",
      "   -2.34765768]\n",
      " [ -3.16366839  -6.27524328  -0.18959212 ...,   5.3775568   -1.33155012\n",
      "   -1.25523257]\n",
      " ..., \n",
      " [ -7.9624629    3.3482852    7.71547127 ...,   5.91617012   4.04497671\n",
      "    2.27989793]\n",
      " [ -3.23057485   4.60989571   5.82851648 ...,   3.45486617   1.28478599\n",
      "    0.23329422]\n",
      " [ -9.43785954   4.39097881  10.85242271 ...,   4.54710913   1.99141037\n",
      "    1.45276427]]\n",
      "Check GPU result with CPU result if they are the same :\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "print(predict_dev)\n",
    "print(\"Check GPU result with CPU result if they are the same :\")\n",
    "print(np.linalg.norm(predict_dev.get() - batchTrain.dot(NN_dev.get())) / np.linalg.norm(batchTrain.dot(NN_dev.get())) < 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-reading: http://cs231n.github.io/linear-classify/#softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.20096382e-04,   1.80313174e-04,   6.61071739e-04, ...,\n",
       "          9.70663309e-01,   6.32582839e-07,   3.96009182e-06],\n",
       "       [  4.65533745e-08,   1.14831177e-03,   3.78643751e-01, ...,\n",
       "          6.00694358e-01,   6.38207493e-05,   7.59502233e-04],\n",
       "       [  1.57253089e-04,   7.00260625e-06,   3.07768444e-03, ...,\n",
       "          8.05390060e-01,   9.82376863e-04,   1.06028432e-03],\n",
       "       ..., \n",
       "       [  1.22112780e-07,   9.97600891e-03,   7.86324203e-01, ...,\n",
       "          1.30069375e-01,   2.00228598e-02,   3.42737813e-03],\n",
       "       [  1.30953458e-05,   3.32805067e-02,   1.12571947e-01, ...,\n",
       "          1.04849674e-02,   1.19705254e-03,   4.18269279e-04],\n",
       "       [  1.51609614e-09,   1.53643906e-03,   9.83297110e-01, ...,\n",
       "          1.79606408e-03,   1.39442753e-04,   8.13701408e-05]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU softmax fun'\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_softmax(\n",
    "    GLOBAL_MEM float *input\n",
    "    )\n",
    "{\n",
    "    const SIZE_T i0 = get_global_id(0);\n",
    "    const SIZE_T i1 = get_global_id(1);\n",
    "    //why terminate?  because softmax need to sum up from [i,0] to [i,end]\n",
    "    if(i1>0)return;\n",
    "\n",
    "    int IDX = i0*get_global_size(1)+i1;\n",
    "    float s = 0.0;\n",
    "    float max = 0.0;\n",
    "    for(int i=0;i<get_global_size(1);i++){\n",
    "        if(max<input[IDX+i])max=input[IDX+i];\n",
    "    }\n",
    "    for(int i=0;i<get_global_size(1);i++){\n",
    "      input[IDX+i]=exp(input[IDX+i]-max);\n",
    "      s+=input[IDX+i];\n",
    "    };\n",
    "    for(int i=0;i<get_global_size(1);i++){\n",
    "      input[IDX+i]/=s;\n",
    "    };\n",
    "}\n",
    "\"\"\")\n",
    "GPUsoftmax = program.gpu_softmax\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "predict_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.10526034e-03,   2.36217733e-02,   3.41599365e-03, ...,\n",
       "         -9.87945318e-01,   1.69304222e-01,   1.57591549e-03],\n",
       "       [  6.69368878e-02,   5.01299463e-03,   3.07187557e-01, ...,\n",
       "         -7.53791332e-01,   8.32950845e-02,   2.66553257e-02],\n",
       "       [  1.71011857e-06,   7.38984440e-04,   6.61693321e-06, ...,\n",
       "          1.13188245e-04,   2.92522600e-04,   2.29449256e-06],\n",
       "       ..., \n",
       "       [ -9.99879658e-01,   8.34345166e-03,   1.51391199e-04, ...,\n",
       "          1.00565485e-05,   2.00507187e-04,   1.46632592e-05],\n",
       "       [  2.39652756e-04,   1.04264647e-01,   2.77398364e-03, ...,\n",
       "          1.43363429e-02,   1.28449360e-02,   1.52608831e-04],\n",
       "       [  8.57720908e-04,   6.90310895e-01,   6.23268681e-03, ...,\n",
       "          4.25609313e-02,   9.19866040e-02,   5.38685685e-03]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchIdx = getRandBatch()\n",
    "batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "# GPUrearrange(NN_dev, (np.float32)(0), (np.float32)(0.1), local_size=(1,1), global_size=NN_dev.shape)\n",
    "\n",
    "GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "'calculate errors cross entropy'\n",
    "errors_dev=(predict_dev-batchTrainLabels_dev)\n",
    "errors_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"get errors like this : errors_dev=batchTrainLabels_dev-predict_dev\"\n",
    "\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_minus(\n",
    "    GLOBAL_MEM float *a_dev,\n",
    "    GLOBAL_MEM float *b_dev,\n",
    "    GLOBAL_MEM float *res_dev\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    res_dev[IDX] = a_dev[IDX] - b_dev[IDX] ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUminus = program.gpu_minus\n",
    "GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217.10446"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'set up a GPU errors back fun'\n",
    "errors_back_dev = thr.array((layers[0],layers[-1]), dtype=np.float32)\n",
    "\n",
    "GPUerrorsBack = MatrixMul(batchTrain_dev, errors_dev, out_arr=errors_back_dev, transposed_a=True).compile(thr)\n",
    "GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "errors_back_dev.get().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"update weights like this : NN_dev+= lr * errors_back_dev/batchSize\"\n",
    "\n",
    "program = thr.compile(\"\"\"\n",
    "KERNEL void gpu_updateW(\n",
    "    GLOBAL_MEM float *NN_dev,\n",
    "    GLOBAL_MEM float *errors_back_dev,\n",
    "    const float lr,\n",
    "    const float batchSize\n",
    "    )\n",
    "{\n",
    "    const SIZE_T id0 = get_global_id(0);\n",
    "    const SIZE_T id1 = get_global_id(1);\n",
    "    int IDX = id0*get_global_size(1)+id1;\n",
    "    NN_dev[IDX] += lr * errors_back_dev[IDX]/batchSize ; \n",
    "}\n",
    "\"\"\")\n",
    "GPUupdateW = program.gpu_updateW\n",
    "GPUupdateW(NN_dev, errors_back_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GPU_randomSet(counters_dev, NN_dev)\n",
    "GPUrearrange(NN_dev, (np.float32)(0), (np.float32)(0.1), local_size=(1,1), global_size=NN_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "# batchTrain_dev = thr.to_device(X_train[:,:].astype(np.float32))\n",
    "# batchTrainLabels_dev = thr.to_device(y_train[:,:].astype(np.float32))\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrain_dev = thr.to_device(batchTrain)\n",
    "\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels_dev = thr.to_device(batchTrainLabels)\n",
    "\n",
    "    GPUfeedforward(predict_dev, batchTrain_dev, NN_dev)\n",
    "    GPUsoftmax(predict_dev, local_size=(1,1), global_size=predict_dev.shape)\n",
    "\n",
    "    'calculate errors cross entropy'\n",
    "    GPUminus(batchTrainLabels_dev, predict_dev, errors_dev, local_size=(1,1), global_size=errors_dev.shape)\n",
    "    GPUerrorsBack(errors_back_dev, batchTrain_dev, errors_dev)\n",
    "#     errors_mean_dev=errors_back_dev/batchSize\n",
    "    GPUupdateW(NN_dev, errors_dev, (np.float32)(lr), (np.float32)(batchSize), local_size=(1,1), global_size=errors_dev.shape)\n",
    "#     if i%100 == 0:\n",
    "#         print((np.argmax(predict_dev.get(),1)==np.argmax(batchTrainLabels,1)).sum()/batchSize*100)\n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. make a CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    tmp=np.exp(x-x.max(1).reshape(-1,1))\n",
    "    return tmp/tmp.sum(1).reshape(-1,1)\n",
    "NN=NN_dev.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9 ms\n",
      "Wall time: 3 ms\n",
      "Wall time: 27 ms\n",
      "acc: 14.9\n",
      "cost time: 0.0760042667388916\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "# batchTrain = X_train[:,:].astype(np.float32)\n",
    "# batchTrainLabels = y_train[:,:].astype(np.float32)\n",
    "import time\n",
    "start = time.time()\n",
    "for j in range((int)(1e0)):\n",
    "    batchIdx = getRandBatch()\n",
    "    batchTrain = X_train[batchIdx,:].astype(np.float32)\n",
    "    batchTrainLabels = y_train[batchIdx,:].astype(np.float32)\n",
    "    \n",
    "    %time y = softmax(batchTrain.dot(NN))\n",
    "    %time error = batchTrainLabels - y\n",
    "    %time NN += batchTrain.T.dot(error)/batchSize * lr\n",
    "    \n",
    "    if (j% 100) == 0:\n",
    "        print(\"acc:\",(np.argmax(y,1)==np.argmax(batchTrainLabels,1)).sum()/batchSize*100)   \n",
    "print('cost time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
